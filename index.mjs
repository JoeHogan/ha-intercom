import 'dotenv/config';
import http from 'http';
import path from'path';
import { WebSocketServer } from 'ws';
import express from'express';
import { v4 as uuidv4 } from 'uuid';
import { PassThrough } from 'stream';
import { fileURLToPath } from 'url';
import { spawn } from 'child_process';
import { postSTT } from './server/stt.mjs';
import { postAudio, postAlexaTTS, postTTS } from './server/ha.mjs';
import { getMessage, encodeMessage } from './server/ws.mjs';

const haUrl = process.env.HOME_ASSISTANT_URL;
const token = process.env.HOME_ASSISTANT_ACCESS_TOKEN;
const audioHost = process.env.AUDIO_HOST;
const audioPoolSize = process.env.AUDIO_POOL_SIZE ? parseInt(process.env.AUDIO_POOL_SIZE) : 2; // For audio streaming
const sttPoolSize = process.env.STT_POOL_SIZE ? parseInt(process.env.STT_POOL_SIZE) : 1; // For STT transcription

const app = express();
const server = http.createServer(app);
const port = 3001;
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Global Pools
const ffmpegQueue = [];      // âœ… Audio Streaming (MP3) Pool - Restored
const sttFfmpegQueue = [];   // âœ… STT Processing (WAV) Pool - Restored

// Active Session Maps
const activeFfmpegSessions = new Map(); // Maps wssId -> Audio Instance
const activeSttSessions = new Map(); Â  Â // Maps wssId -> STT Instance

// âœ… SHARED TRACKING: Global tracking array for ALL active FFMPEG PIDs
const activeFfmpegPIDs = []; 

class ClientSession {
Â  Â  constructor(config = {}) {
Â  Â  Â  Â  this.wssId = uuidv4();
Â  Â  Â  Â  this.id = config.id;
Â  Â  Â  Â  this.haUrl = haUrl || config.haUrl;
Â  Â  Â  Â  this.haToken = token || config.haToken;
Â  Â  Â  Â  this.audioHost = audioHost || config.audioHost || `http://localhost:3001`;
Â  Â  }
}

const audioStreams = {};

// --- GLOBAL FACTORY AND HELPER FUNCTIONS (DEFINED ONCE) ---

// ðŸ†• NEW: Centralized Refill Check for both pools
const checkAndRefillPools = () => {
    // Only proceed if NO FFMPEG processes are currently active (streaming or processing)
    if (activeFfmpegPIDs.length === 0) {
        console.log("Pool replenishment condition met: No active FFMPEG PIDs. Refilling both pools.");
        refillFFmpegPool(); // Refills Audio Pool
        refillSttPool(); Â  Â // Refills STT Pool
    } else {
        console.log(`Pool refill skipped: ${activeFfmpegPIDs.length} FFMPEG process(es) still active.`);
    }
};

const createFfmpegInstance = () => {
Â  Â  const child = spawn('ffmpeg', [
Â  Â  Â  Â  '-probesize', '32',
Â  Â  Â  Â  '-analyzeduration', '0',
Â  Â  Â  Â  '-f', 'webm',
Â  Â  Â  Â  '-i', 'pipe:0', 
Â  Â  Â  Â  '-f', 'mp3',
Â  Â  Â  Â  '-acodec', 'libmp3lame',
Â  Â  Â  Â  '-ar', '44100',
Â  Â  Â  Â  '-compression_level', '0', 
Â  Â  Â  Â  '-flush_packets', '1', 
Â  Â  Â  Â  '-'
Â  Â  ]);
Â  Â  const inputPassThrough = new PassThrough();
Â  Â  inputPassThrough.pipe(child.stdin);

Â  Â  child.stderr.on('data', data => {
Â  Â  Â  Â  console.error(`FFMPEG [PID ${child.pid}] (Audio) stderr:`, data.toString());
Â  Â  });
Â  Â  child.on('error', (err) => {
Â  Â  Â  Â  console.error(`FFMPEG [PID ${child.pid}] (Audio) process error:`, err);
Â  Â  });

Â  Â  return { child, input: inputPassThrough, pid: child.pid, active: false };
};

const createSttFfmpegInstance = () => {
Â  Â  const child = spawn('ffmpeg', [
Â  Â  Â  Â  '-f', 'webm', 
Â  Â  Â  Â  '-i', 'pipe:0', 
Â  Â  Â  Â  '-ac', '1', 
Â  Â  Â  Â  '-ar', '16000', 
Â  Â  Â  Â  '-f', 'wav', 
Â  Â  Â  Â  'pipe:1' 
Â  Â  ]);
Â  Â  const inputPassThrough = new PassThrough();
Â  Â  inputPassThrough.pipe(child.stdin);

Â  Â  child.stderr.on('data', data => {
Â  Â  Â  Â  console.error(`FFMPEG [PID ${child.pid}] (STT) stderr:`, data.toString());
Â  Â  });
Â  Â  child.on('error', (err) => {
Â  Â  Â  Â  console.error(`FFMPEG [PID ${child.pid}] (STT) process error:`, err);
Â  Â  });
Â  Â  
Â  Â  const wavChunks = [];
Â  Â  child.stdout.on('data', chunk => {
Â  Â  Â  Â  wavChunks.push(chunk);
Â  Â  });

Â  Â  return { child, input: inputPassThrough, pid: child.pid, active: false, wavChunks };
};

const killInstance = (ffmpeg) => {
Â  Â  if (ffmpeg?.child) {
Â  Â  Â  Â  ffmpeg.input.end();
Â  Â  Â  Â  ffmpeg.child.stdin.end();
Â  Â  Â  Â  ffmpeg.child.kill('SIGKILL');
Â  Â  Â  Â  console.log(`FFMPEG [PID ${ffmpeg.pid}] forcefully terminated.`);
        
        // ðŸš¨ CRITICAL: Remove PID from the global tracking array
        const pidIndex = activeFfmpegPIDs.indexOf(ffmpeg.pid);
        if (pidIndex > -1) {
            activeFfmpegPIDs.splice(pidIndex, 1);
            console.log(`PID ${ffmpeg.pid} removed from active tracking. Remaining PIDs: ${activeFfmpegPIDs.length}`);
        }
        
        // ðŸš¨ CRITICAL: Check and refill pools after killing an instance
        checkAndRefillPools();
Â  Â  }
};

const refillFFmpegPool = () => {
Â  Â  while (ffmpegQueue.length < audioPoolSize) {
Â  Â  Â  Â  console.log("Audio Pool refill initiated...");
Â  Â  Â  Â  const instance = createFfmpegInstance(); 
Â  Â  Â  Â  ffmpegQueue.push(instance);
Â  Â  Â  Â  console.log(`Refilled Audio Pool with [PID ${instance.pid}]. Current size: ${ffmpegQueue.length}`);
Â  Â  }
};

const refillSttPool = () => {
Â  Â  while (sttFfmpegQueue.length < sttPoolSize) {
Â  Â  Â  Â  console.log("STT Pool refill initiated...");
Â  Â  Â  Â  const instance = createSttFfmpegInstance(); 
Â  Â  Â  Â  sttFfmpegQueue.push(instance);
Â  Â  Â  Â  console.log(`Refilled STT Pool with [PID ${instance.pid}]. Current size: ${sttFfmpegQueue.length}`);
Â  Â  }
};

const initializeFFmpegPools = () => {
Â  Â  refillFFmpegPool();
Â  Â  refillSttPool();
};

const getEntitesByType = (targets, type) => {
Â  Â  type = (type || '').toLowerCase();
Â  Â  return targets.filter(item => item.type.toLowerCase().trim() === type);
};

// --- CONNECTION HANDLER FUNCTION ---
const handleConnection = (ws, request) => {
Â  Â  console.log('WebSocket client connected');

Â  Â  let audioEntities;
Â  Â  let ttsEntities;
Â  Â  let alexaEntities;
Â  Â  
Â  Â  const url = new URL(request.url, `http://localhost:${port}`);
Â  Â  const id = url.searchParams.get('id');
Â  Â  const haUrl = url.searchParams.get('haUrl');
Â  Â  const haToken = url.searchParams.get('haToken');
Â  Â  const audioHost = url.searchParams.get('audioHost');
Â  Â  ws.clientId = id; 

Â  Â  const setPlayers = (header) => {
Â  Â  Â  Â  let targets = (header.target || [])
Â  Â  Â  Â  Â  Â  .filter(item => !!item?.entity_id)
Â  Â  Â  Â  Â  Â  .map(item => {
Â  Â  Â  Â  Â  Â  Â  Â  let entity_id = item.entity_id.trim();
Â  Â  Â  Â  Â  Â  Â  Â  let type = entity_id.startsWith('ha_client') ? 'audio' : item.type ? item.type.trim().toLowerCase() : 'tts';
Â  Â  Â  Â  Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  type,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entity_id
Â  Â  Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  .filter((item, i, arr) => arr.findIndex(ai => ai.entity_id === item.entity_id) === i);
Â  Â  Â  Â  audioEntities = getEntitesByType(targets, 'audio');
Â  Â  Â  Â  ttsEntities = getEntitesByType(targets, 'tts');
Â  Â  Â  Â  alexaEntities = getEntitesByType(targets, 'alexa');
Â  Â  };

Â  Â  // --- Core Logic Functions (defined within handler to access client-specific state) ---

Â  Â  const startAudio = (clientSession) => { 

Â  Â  Â  Â  if(!audioEntities.length) {
Â  Â  Â  Â  Â  Â  return null;
Â  Â  Â  Â  }

Â  Â  Â  Â  let currentInstance = ffmpegQueue.pop(); 

Â  Â  Â  Â  if (!currentInstance) {
Â  Â  Â  Â  Â  Â  console.warn("Audio Pool empty. Synchronously creating a temporary instance.");
Â  Â  Â  Â  Â  Â  currentInstance = createFfmpegInstance(); 
Â  Â  Â  Â  }

Â  Â  Â  Â  activeFfmpegSessions.set(clientSession.wssId, currentInstance); 
Â  Â  Â  Â  currentInstance.active = true;
        
        // ðŸš¨ ADDED: Add Audio PID to the shared tracking array
        activeFfmpegPIDs.push(currentInstance.pid);

Â  Â  Â  Â  console.log(`WS ${clientSession.wssId} started AUDIO session with FFMPEG [PID ${currentInstance.pid}]. Active PIDs: ${activeFfmpegPIDs.length}`);
Â  Â  Â  Â  
Â  Â  Â  Â  const audioStream = new PassThrough();
Â  Â  Â  Â  audioStreams[clientSession.wssId] = audioStream; 
        currentInstance.audioStream = audioStream;

Â  Â  Â  Â  console.log(`${clientSession.wssId}: Sending AUDIO (MP3) to ${audioEntities.map(({entity_id}) => entity_id).join(', ')}`);

Â  Â  Â  Â  let haClients = audioEntities.filter(item => item.entity_id.startsWith('ha_client'));
Â  Â  Â  Â  let audioClients = audioEntities.filter(item => !item.entity_id.startsWith('ha_client'));
Â  Â  Â  Â  postAudio(clientSession, audioClients);

Â  Â  Â  Â  currentInstance.child.stdout.removeAllListeners('data'); 

Â  Â  Â  Â  currentInstance.child.stdout.on('data', chunk => {
Â  Â  Â  Â  Â  Â  let buffer = Buffer.from(chunk);
Â  Â  Â  Â  Â  Â  if (currentInstance.audioStream?.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  currentInstance.audioStream.write(buffer);
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if(haClients.length) {
Â  Â  Â  Â  Â  Â  Â  Â  let haClientIds = haClients.filter(item => !!item.entity_id).map(item => item.entity_id.split('.')[item.entity_id.split('.').length -1]);
Â  Â  Â  Â  Â  Â  Â  Â  wss.clients
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .forEach((item) => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if(item.clientId && haClientIds.indexOf(item.clientId) > -1) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  item.send(encodeMessage({type: 'audio', from: clientSession.id}, buffer).toJSON());
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  });
Â  Â  Â  Â  
Â  Â  Â  Â  currentInstance.onStdoutEnd = () => {
Â  Â  Â  Â  Â  Â  if (currentInstance.audioStream?.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  Â console.log(`FFMPEG [PID ${currentInstance.pid}] stdout closed. Ending PassThrough stream.`);
Â  Â  Â  Â  Â  Â  Â  Â  currentInstance.audioStream.end();
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  };
Â  Â  Â  Â  currentInstance.child.stdout.removeAllListeners('end');
Â  Â  Â  Â  currentInstance.child.stdout.on('end', currentInstance.onStdoutEnd); 

Â  Â  Â  Â  const onStreamClose = () => {
Â  Â  Â  Â  Â  Â  console.log(`PassThrough stream for ${clientSession.wssId} closed.`);
Â  Â  Â  Â  Â  Â  delete audioStreams[clientSession.wssId];
            currentInstance.child.stdout.removeAllListeners('data');
            if (currentInstance.onStdoutEnd) {
                currentInstance.child.stdout.removeListener('end', currentInstance.onStdoutEnd);
                delete currentInstance.onStdoutEnd;
            }
            delete currentInstance.audioStream;
Â  Â  Â  Â  };

Â  Â  Â  Â  audioStream.on('close', onStreamClose);
Â  Â  };

Â  Â  const startSTT = (clientSession) => { 

Â  Â  Â  Â  if((ttsEntities.length + alexaEntities.length) === 0) {
Â  Â  Â  Â  Â  Â  return null;
Â  Â  Â  Â  }

Â  Â  Â  Â  let currentInstance = sttFfmpegQueue.pop(); // ðŸ’¡ Get from dedicated STT pool

Â  Â  Â  Â  if (!currentInstance) {
Â  Â  Â  Â  Â  Â  console.warn("STT Pool empty. Synchronously creating a temporary instance.");
Â  Â  Â  Â  Â  Â  currentInstance = createSttFfmpegInstance();
Â  Â  Â  Â  }

Â  Â  Â  Â  activeSttSessions.set(clientSession.wssId, currentInstance);
Â  Â  Â  Â  currentInstance.active = true;
        
        // ðŸš¨ ADDED: Add STT PID to the shared tracking array
        activeFfmpegPIDs.push(currentInstance.pid);
Â  Â  Â  Â  
Â  Â  Â  Â  console.log(`WS ${clientSession.wssId} started STT session with FFMPEG [PID ${currentInstance.pid}]. Active PIDs: ${activeFfmpegPIDs.length}`);

Â  Â  Â  Â  // âŒ REMOVED: Refill logic is now in checkAndRefillPools() triggered by killInstance()

Â  Â  Â  Â  currentInstance.child.stdout.removeAllListeners('end'); 

Â  Â  Â  Â  currentInstance.child.stdout.on('end', async () => {
Â  Â  Â  Â  Â  Â  const wavBuffer = Buffer.concat(currentInstance.wavChunks);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  currentInstance.wavChunks.length = 0; 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  postSTT(wavBuffer)
Â  Â  Â  Â  Â  Â  Â  Â  .then((res) => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  let message = res?.text?.trim();
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.send(encodeMessage({type: 'transcription', text: (message || '[no text]')}).toJSON());
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if (message) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if(ttsEntities.length) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.log(`${clientSession.wssId}: Sending TTS to ${ttsEntities.map(({entity_id}) => entity_id).join(', ')}`);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  postTTS(clientSession, message, ttsEntities);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if(alexaEntities.length) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.log(`${clientSession.wssId}: Sending ALEXA TTS to ${alexaEntities.map(({entity_id}) => entity_id).join(', ')}`);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  postAlexaTTS(clientSession, message, alexaEntities);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  Â  Â  .catch(() => ws.send(encodeMessage({type: 'transcription', text: '[error transcribing audio]'}).toJSON()));
Â  Â  Â  Â  });
Â  Â  Â  Â  
Â  Â  Â  Â  return currentInstance;
Â  Â  };


Â  Â  const stop = (clientSession) => { 
Â  Â  Â  Â  // --- STT Cleanup ---
Â  Â  Â  Â  const sttInstanceToKill = activeSttSessions.get(clientSession.wssId);
Â  Â  Â  Â  
Â  Â  Â  Â  if (sttInstanceToKill) {
Â  Â  Â  Â  Â  Â  if (sttInstanceToKill.input.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`FFMPEG [PID ${sttInstanceToKill.pid}] STT input closed (EOF signal).`);
Â  Â  Â  Â  Â  Â  Â  Â  sttInstanceToKill.input.end();
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  sttInstanceToKill.active = false;
Â  Â  Â  Â  Â  Â  activeSttSessions.delete(clientSession.wssId);

Â  Â  Â  Â  Â  Â  // Kill instance after delay (killInstance handles PID removal and pool check)
Â  Â  Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  Â  Â  killInstance(sttInstanceToKill); 
Â  Â  Â  Â  Â  Â  }, 500); 
Â  Â  Â  Â  }

Â  Â  Â  Â  // --- Audio Cleanup ---
Â  Â  Â  Â  const audioInstanceToKill = activeFfmpegSessions.get(clientSession.wssId);
Â  Â  Â  Â  
Â  Â  Â  Â  if (audioInstanceToKill) {
Â  Â  Â  Â  Â  Â  if (audioInstanceToKill.input.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  console.log(`FFMPEG [PID ${audioInstanceToKill.pid}] Audio input closed (EOF signal).`);
Â  Â  Â  Â  Â  Â  Â  Â  audioInstanceToKill.input.end();
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  audioInstanceToKill.active = false;
Â  Â  Â  Â  Â  Â  activeFfmpegSessions.delete(clientSession.wssId);

            if (audioInstanceToKill.onStdoutEnd) {
                audioInstanceToKill.child.stdout.removeListener('end', audioInstanceToKill.onStdoutEnd);
                delete audioInstanceToKill.onStdoutEnd;
            }
            delete audioInstanceToKill.audioStream;

Â  Â  Â  Â  Â  Â  console.log(`FFMPEG [PID ${audioInstanceToKill.pid}] released. Scheduling Audio cleanup in 5s...`);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Kill instance after delay (killInstance handles PID removal and pool check)
Â  Â  Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  Â  Â  const audioStream = audioStreams[clientSession.wssId];
Â  Â  Â  Â  Â  Â  Â  Â  if(audioStream && audioStream.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  console.warn(`[PID ${audioInstanceToKill.pid}] Forced audio stream closure before killing.`);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  audioStream.end(); 
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  killInstance(audioInstanceToKill);
Â  Â  Â  Â  Â  Â  }, 5000); 
Â  Â  Â  Â  }
Â  Â  };

Â  Â  // --- WebSocket Event Handlers ---
Â  Â  ws.on('message', data => {

Â  Â  Â  Â  const {header, payload} = getMessage(data);

        let currentTransactionSession = ws.currentTransactionSession;
Â  Â  Â  
Â  Â  Â  Â  if(header.type === 'ping') {
Â  Â  Â  Â  Â  Â  ws.send(encodeMessage({type: 'pong'}));
Â  Â  Â  Â  }
        
Â  Â  Â  Â  if(header.type === 'start') {
            currentTransactionSession = new ClientSession({
                id, 
                haUrl, 
                haToken, 
                audioHost
            });
            ws.currentTransactionSession = currentTransactionSession;
            
Â  Â  Â  Â  Â  Â  setPlayers(header);
Â  Â  Â  Â  Â  Â  console.log([`Client ID: ${currentTransactionSession.id || 'Not Set'}`, `Session ID: ${currentTransactionSession.wssId}`, `HA Url: ${currentTransactionSession.haUrl}`, `Audio Host Url: ${currentTransactionSession.audioHost}`, `HA Token present: ${currentTransactionSession.haToken ? 'TRUE' : 'FALSE'}`].join(' | '));
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  startAudio(currentTransactionSession); 
Â  Â  Â  Â  Â  Â  startSTT(currentTransactionSession); 
Â  Â  Â  Â  }
        
Â  Â  Â  Â  if(header.type === 'stop') {
            if (!currentTransactionSession) {
                console.warn("Received 'stop' without active session context.");
                return;
            }
Â  Â  Â  Â  Â  Â  stop(currentTransactionSession); 
            delete ws.currentTransactionSession;
Â  Â  Â  Â  }
        
Â  Â  Â  Â  if(header.type === 'data') {
            if (!currentTransactionSession) {
                return;
            }

            // Look up instances using the current unique wssId
Â  Â  Â  Â  Â  Â  const currentActiveAudioInstance = activeFfmpegSessions.get(currentTransactionSession.wssId);
Â  Â  Â  Â  Â  Â  const currentActiveSttInstance = activeSttSessions.get(currentTransactionSession.wssId);

Â  Â  Â  Â  Â  Â  if (currentActiveAudioInstance?.active && currentActiveAudioInstance.input.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  currentActiveAudioInstance.input.write(payload);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  if (currentActiveSttInstance?.active && currentActiveSttInstance.input.writable) {
Â  Â  Â  Â  Â  Â  Â  Â  currentActiveSttInstance.input.write(payload);
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  });

Â  Â  ws.on('close', (code, reason) => {
Â  Â  Â  Â  console.log(`Client disconnected: ${code}, ${reason}`);
Â  Â  Â  Â  
        const closedSession = ws.currentTransactionSession;
        if (!closedSession) return; 
        
Â  Â  Â  Â  const activeAudioInstance = activeFfmpegSessions.get(closedSession.wssId);
        // Note: killInstance handles removing the PID and checking for pool refill
Â  Â  Â  Â  if (activeAudioInstance) {
Â  Â  Â  Â  Â  Â  killInstance(activeAudioInstance);
Â  Â  Â  Â  Â  Â  activeFfmpegSessions.delete(closedSession.wssId);
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  const activeSttInstance = activeSttSessions.get(closedSession.wssId);
Â  Â  Â  Â  if (activeSttInstance) {
Â  Â  Â  Â  Â  Â  // Note: killInstance handles removing the PID and checking for pool refill
Â  Â  Â  Â  Â  Â  killInstance(activeSttInstance);
Â  Â  Â  Â  Â  Â  activeSttSessions.delete(closedSession.wssId);
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  if (audioStreams[closedSession.wssId]) {
Â  Â  Â  Â  Â  Â  Â audioStreams[closedSession.wssId].end();
Â  Â  Â  Â  Â  Â   delete audioStreams[closedSession.wssId];
Â  Â  Â  Â  }
        delete ws.currentTransactionSession;
Â  Â  });

};
// --- END OF CONNECTION HANDLER FUNCTION ---

app.use(express.static('custom_components/ha_intercom/www'));

const wss = new WebSocketServer({ noServer: true });

wss.on('connection', handleConnection); 

// --- EXECUTE POOL INITIALIZATION ---
initializeFFmpegPools();
// -----------------------------------

server.on('upgrade', (request, socket, head) => {
Â  if (request.url.startsWith('/api/ha_intercom/ws')) {
Â  Â  wss.handleUpgrade(request, socket, head, (ws) => {
Â  Â  Â  wss.emit('connection', ws, request);
Â  Â  });
Â  } else {
Â  Â  socket.destroy();
Â  }
});

app.get('/listen/:wssId/audio.mp3', (req, res) => {
Â  Â  const wssId = req.params.wssId;
Â  Â  const audioStream = audioStreams[wssId];
Â  Â  if (audioStream) {
Â  Â  Â  Â  console.log(`${wssId}: Streaming AUDIO (MP3) to client...`);
Â  Â  Â  Â  res.setHeader('Content-Type', 'audio/mpeg');
Â  Â  Â  Â  res.setHeader('Transfer-Encoding', 'chunked');
Â  Â  Â  Â  audioStream.pipe(res);
Â  Â  } else {
Â  Â  Â  Â  console.error(`${wssId}: Failed to stream AUDIO to client: Audio Stream not found.`);
Â  Â  Â  Â  res.status(400).send({message: `No audio stream available`});
Â  Â  }
});

app.get('/', (req, res) => {
Â  Â  res.sendFile('index.html', {root: path.join(__dirname, '/src')});
});

server.listen(port, () => {
Â  Â  console.log(`WebSocket server listening on port ${port}`);
});